{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8cd6b0",
   "metadata": {},
   "source": [
    "# Homework\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a38670",
   "metadata": {},
   "source": [
    "## Load libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b310b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml libraries\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70fc7e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99464ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = pd.read_parquet('./data/yellow_tripdata_2023-01.parquet')\n",
    "feb_df = pd.read_parquet('./data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d231aa",
   "metadata": {},
   "source": [
    "### Q1. Downloading the data\n",
    "- We'll use the same  [NYC taxi dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page), but instead of \"Green Taxi Trip  Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "- Download the data for January and February 2023.\n",
    "\n",
    "- Read the data for January. How many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba920a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "There are {len(jan_df.columns)} columns.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b986a",
   "metadata": {},
   "source": [
    "### Q2. Computing duration\n",
    "- Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "- What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e594f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps we create the duration column from pickup and dropoff datetime\n",
    "jan_df['duration(min)'] = (jan_df['tpep_dropoff_datetime'] - jan_df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "results = jan_df['duration(min)'].describe()\n",
    "print(f'''\n",
    "the std of the duration is {results['std']:.2f} minutes\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17be4e",
   "metadata": {},
   "source": [
    "### Q3. Dropping outliers\n",
    "- Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "- What fraction of the records left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26002746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers with duration > 60 minutes\n",
    "value_before = len(jan_df)\n",
    "jan_df = jan_df[(jan_df['duration(min)'] >= 1) & (jan_df['duration(min)'] <= 60)]\n",
    "jan_df['duration(min)'].describe()\n",
    "print(f'''\n",
    "the numer of rows before removing outliers is {value_before}\n",
    "The number of rows after removing outliers is {len(jan_df)}.\n",
    "The percentage of rows removed is {100 * (value_before - len(jan_df)) / value_before:.2f}%\n",
    "The percentage of rows kept is {100 * len(jan_df) / value_before:.2f}%\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd43c0",
   "metadata": {},
   "source": [
    "### Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the oickup and dropoff locations ids\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "jan_df[categorical] = jan_df[categorical].astype(str)\n",
    "\n",
    "train_dic = jan_df[categorical].to_dict(orient='records')\n",
    "dv= DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dic)\n",
    "\n",
    "# Get number of features (columns)\n",
    "n_features = X_train.shape[1]\n",
    "print(f'Number of features (columns) in the matrix: {n_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404df07",
   "metadata": {},
   "source": [
    "### Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "- Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "- Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f696f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr  = LinearRegression()\n",
    "y_train = jan_df['duration(min)'].values\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_train)\n",
    "rmse = root_mean_squared_error(y_train, y_pred)\n",
    "print(f'''\n",
    "The RMSE of the model is {rmse:.2f} minutes\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f31ed7",
   "metadata": {},
   "source": [
    "### Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "- What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82867a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate duration for February data\n",
    "feb_df['duration(min)'] = (feb_df['tpep_dropoff_datetime'] - feb_df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter outliers like we did with January data\n",
    "feb_df = feb_df[(feb_df['duration(min)'] >= 1) & (feb_df['duration(min)'] <= 60)]\n",
    "\n",
    "# Prepare features - convert to string type\n",
    "feb_df[categorical] = feb_df[categorical].astype(str)\n",
    "\n",
    "# Create feature matrix using the same DictVectorizer\n",
    "val_dict = feb_df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)  # Note: using transform, not fit_transform\n",
    "\n",
    "# Make predictions\n",
    "y_val = feb_df['duration(min)'].values\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "val_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print(f'RMSE on validation data: {val_rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
